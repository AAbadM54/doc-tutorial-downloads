{"nbformat_minor": 1, "cells": [{"source": "<table style=\"border: none\" align=\"left\">\n    <tr style=\"border: none\">\n       <th style=\"border: none\"><img src=\"https://raw.githubusercontent.com/pmservice/cars-4-you/master/static/images/logo.png\" width=\"200\" alt=\"Icon\"></th>\n       <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Action Recommendation</b></th>\n   </tr>\n</table>", "cell_type": "markdown", "metadata": {}}, {"source": "<img align=left src=\"https://github.com/pmservice/cars-4-you/raw/master/static/images/action.png\" width=\"550\" alt=\"Icon\">", "cell_type": "markdown", "metadata": {}}, {"source": "Contents\n- [0. Setup](#setup)\n- [1. Introduction](#introduction)\n- [2. Load and explore data](#load)\n- [3. Create an Apache Spark machine learning model](#model)\n- [4. Store the model in the Watson Machine Learning repository](#persistence)\n- [5. Deploy the model in the IBM Cloud](#persistence)\n- [6. Score the model](#score)", "cell_type": "markdown", "metadata": {}}, {"source": "**Note:** This notebook works correctly with kernel `Python 3.5 with Spark 2.1`.", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"setup\"></a>\n## 0. Setup\n\nIn this section please use below cell to upgrade the `watson-machine-learning-client`.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 1, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Collecting watson-machine-learning-client\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/53/6bdafebda644e2245fc860ea99300104523665203fc18f1af18bf5124e31/watson_machine_learning_client-1.0.328-py3-none-any.whl (932kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 942kB 1.1MB/s eta 0:00:01\n\u001b[?25hRequirement not upgraded as not directly required: tqdm in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from watson-machine-learning-client) (4.23.4)\nRequirement not upgraded as not directly required: tabulate in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from watson-machine-learning-client) (0.8.2)\nRequirement not upgraded as not directly required: urllib3 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from watson-machine-learning-client) (1.23)\nRequirement not upgraded as not directly required: certifi in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from watson-machine-learning-client) (2018.4.16)\nRequirement not upgraded as not directly required: pandas in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from watson-machine-learning-client) (0.23.1)\nRequirement not upgraded as not directly required: lomond in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from watson-machine-learning-client) (0.3.1)\nRequirement not upgraded as not directly required: ibm-cos-sdk in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from watson-machine-learning-client) (2.1.1)\nRequirement not upgraded as not directly required: requests in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from watson-machine-learning-client) (2.19.1)\nRequirement not upgraded as not directly required: pytz>=2011k in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client) (2018.4)\nRequirement not upgraded as not directly required: numpy>=1.9.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client) (1.14.5)\nRequirement not upgraded as not directly required: python-dateutil>=2.5.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from pandas->watson-machine-learning-client) (2.7.3)\nRequirement not upgraded as not directly required: six>=1.10.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from lomond->watson-machine-learning-client) (1.11.0)\nRequirement not upgraded as not directly required: ibm-cos-sdk-core==2.*,>=2.0.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.1.1)\nRequirement not upgraded as not directly required: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.1.1)\nRequirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from requests->watson-machine-learning-client) (3.0.4)\nRequirement not upgraded as not directly required: idna<2.8,>=2.5 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s86b-18e61b28c674e4-3fbaf243aed6/.local/lib/python3.5/site-packages (from requests->watson-machine-learning-client) (2.7)\nRequirement not upgraded as not directly required: docutils>=0.10 in /usr/local/src/conda3_runtime.v43/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.14)\nRequirement not upgraded as not directly required: jmespath<1.0.0,>=0.7.1 in /usr/local/src/conda3_runtime.v43/home/envs/DSX-Python35-Spark/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client) (0.9.3)\n\u001b[31mtensorflow 1.3.0 requires tensorflow-tensorboard<0.2.0,>=0.1.0, which is not installed.\u001b[0m\nInstalling collected packages: watson-machine-learning-client\n  Found existing installation: watson-machine-learning-client 1.0.269\n    Uninstalling watson-machine-learning-client-1.0.269:\n      Successfully uninstalled watson-machine-learning-client-1.0.269\nSuccessfully installed watson-machine-learning-client-1.0.328\n"}], "source": "!rm -rf $PIP_BUILD\n!pip install --upgrade watson-machine-learning-client"}, {"source": "**Note**: Please restart the kernel (Kernel -> Restart)", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"introduction\"></a>\n## 1. Introduction\n\nThis notebook defines, trains and deploys the model that recommends specific Action for unstatisfied customers.", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"load\"></a>\n## 2. Load and explore data", "cell_type": "markdown", "metadata": {}}, {"source": "In this section you will load the data as an Apache Spark DataFrame and perform a basic exploration.", "cell_type": "markdown", "metadata": {}}, {"source": "Read data into Spark DataFrame from DB2 database and show sample record.", "cell_type": "markdown", "metadata": {}}, {"source": "### Load data", "cell_type": "markdown", "metadata": {}}, {"source": "**TIP:** Put your service credentials here. Just copy paste content of Credentials tab from service details (IBM Cloud)", "cell_type": "markdown", "metadata": {}}, {"execution_count": 33, "cell_type": "code", "metadata": {}, "outputs": [], "source": "db2_service_credentials = {\n  \"username\": \"***\",\n  \"ssljdbcurl\": \"***\",\n  \"host\": \"***\",\n  \"https_url\": \"***\",\n  \"dsn\": \"***\",\n  \"hostname\": \"***\",\n  \"jdbcurl\": \"***\",\n  \"ssldsn\": \"***\",\n  \"uri\": \"***\",\n  \"password\": \"***\"\n}"}, {"execution_count": 34, "cell_type": "code", "metadata": {}, "outputs": [], "source": "# The code was removed by Watson Studio for sharing."}, {"execution_count": 35, "cell_type": "code", "metadata": {}, "outputs": [], "source": "properties_db2 = {\n    'driver': 'com.ibm.db2.jcc.DB2Driver',\n    'jdbcurl': db2_service_credentials['jdbcurl'],\n    'user': db2_service_credentials['username'],\n    'password': db2_service_credentials['password']\n}"}, {"execution_count": 63, "cell_type": "code", "metadata": {}, "outputs": [{"execution_count": 63, "metadata": {}, "data": {"text/plain": "Row(ID=10, Gender='Male', Status='M', Children=1, Age=Decimal('46.000000'), Customer_Status='Inactive', Car_Owner='Yes', Customer_Service='They did not have the car I wanted.  upgraded me to a car I did not like and did not want.', Satisfaction=0, Business_Area='Product: Availability/Variety/Size', Action='Free Upgrade')"}, "output_type": "execute_result"}], "source": "from pyspark.sql import SparkSession\nimport json\n\nspark = SparkSession.builder.getOrCreate()\ntable_name = 'CAR_RENTAL_TRAINING'\ndf_data = spark.read.jdbc(properties_db2['jdbcurl'], table='.'.join([properties_db2['user'], table_name]), properties=properties_db2)\ndf_data.head()"}, {"source": "### Explore data", "cell_type": "markdown", "metadata": {}}, {"execution_count": 37, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- ID: integer (nullable = true)\n |-- Gender: string (nullable = true)\n |-- Status: string (nullable = true)\n |-- Children: integer (nullable = true)\n |-- Age: decimal(14,6) (nullable = true)\n |-- Customer_Status: string (nullable = true)\n |-- Car_Owner: string (nullable = true)\n |-- Customer_Service: string (nullable = true)\n |-- Satisfaction: integer (nullable = true)\n |-- Business_Area: string (nullable = true)\n |-- Action: string (nullable = true)\n\n"}], "source": "df_data.printSchema()"}, {"source": "**Tip:** Code above can be inserted using Data menu.  You have to select `Insert SparkSession DataFrame` option.\n\n**Note:** Inserted code is modified to work with code in cells below.", "cell_type": "markdown", "metadata": {}}, {"source": "As you can see, the data contains eleven fields. `Action` field is the one you would like to predict using feedback data in `Customer_Service` field.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 38, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Number of records: 243\n"}], "source": "print(\"Number of records: \" + str(df_data.count()))"}, {"execution_count": 39, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------------------------------+-----+\n|Business_area                     |count|\n+----------------------------------+-----+\n|Service: Accessibility            |13   |\n|Product: Functioning              |75   |\n|Service: Attitude                 |12   |\n|Service: Orders/Contracts         |16   |\n|Product: Availability/Variety/Size|21   |\n|Product: Pricing and Billing      |12   |\n|Product: Information              |4    |\n|Service: Knowledge                |90   |\n+----------------------------------+-----+\n\n"}], "source": "df_data.select('Business_area').groupBy('Business_area').count().show(truncate=False)"}, {"execution_count": 40, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-------------------------+-----+\n|Action                   |count|\n+-------------------------+-----+\n|NA                       |137  |\n|Voucher                  |21   |\n|Premium features         |15   |\n|On-demand pickup location|28   |\n|Free Upgrade             |42   |\n+-------------------------+-----+\n\n"}], "source": "df_data.select('Action').groupBy('Action').count().show(truncate=False)"}, {"source": "<a id=\"model\"></a>\n## 3. Create an Apache Spark machine learning model\n\nIn this section you will learn how to:\n\n- [3.1 Prepare data for training a model](#prep)\n- [3.2 Create an Apache Spark machine learning pipeline](#pipe)\n- [3.3 Train a model](#train)", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"prep\"></a>\n### 3.1 Prepare data for training a model\n\nIn this subsection you will split your data into: train and test data set.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 41, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Number of training records: 200\nNumber of testing records : 43\n"}], "source": "train_data, test_data = df_data.randomSplit([0.8, 0.2], 24)\n\nprint(\"Number of training records: \" + str(train_data.count()))\nprint(\"Number of testing records : \" + str(test_data.count()))"}, {"source": "### 3.2 Create the pipeline<a id=\"pipe\"></a>", "cell_type": "markdown", "metadata": {}}, {"source": "In this section you will create an Apache Spark machine learning pipeline and then train the model.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 42, "cell_type": "code", "metadata": {}, "outputs": [], "source": "from pyspark.ml.feature import OneHotEncoder, StringIndexer, IndexToString, VectorAssembler, HashingTF, IDF, Tokenizer\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model"}, {"source": "In the following step, use the StringIndexer transformer to convert all the string fields to numeric ones.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 43, "cell_type": "code", "metadata": {}, "outputs": [], "source": "string_indexer_gender = StringIndexer(inputCol=\"Gender\", outputCol=\"gender_ix\")\nstring_indexer_customer_status = StringIndexer(inputCol=\"Customer_Status\", outputCol=\"customer_status_ix\")\nstring_indexer_status = StringIndexer(inputCol=\"Status\", outputCol=\"status_ix\")\nstring_indexer_owner = StringIndexer(inputCol=\"Car_Owner\", outputCol=\"owner_ix\")\nstring_business_area = StringIndexer(inputCol=\"Business_Area\", outputCol=\"area_ix\")"}, {"execution_count": 44, "cell_type": "code", "metadata": {}, "outputs": [], "source": "assembler = VectorAssembler(inputCols=[\"gender_ix\", \"customer_status_ix\", \"status_ix\", \"owner_ix\", \"area_ix\", \"Children\", \"Age\", \"Satisfaction\"], outputCol=\"features\")"}, {"execution_count": 45, "cell_type": "code", "metadata": {}, "outputs": [], "source": "string_indexer_action = StringIndexer(inputCol=\"Action\", outputCol=\"label\").fit(df_data)"}, {"execution_count": 46, "cell_type": "code", "metadata": {}, "outputs": [], "source": "label_action_converter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\", labels=string_indexer_action.labels)"}, {"execution_count": 47, "cell_type": "code", "metadata": {}, "outputs": [], "source": "dt_action = DecisionTreeClassifier()"}, {"execution_count": 48, "cell_type": "code", "metadata": {}, "outputs": [], "source": "pipeline_action = Pipeline(stages=[string_indexer_gender, string_indexer_customer_status, string_indexer_status, string_indexer_action, string_indexer_owner, string_business_area, assembler, dt_action, label_action_converter])"}, {"execution_count": 49, "cell_type": "code", "metadata": {}, "outputs": [], "source": "model_action = pipeline_action.fit(train_data)"}, {"execution_count": 50, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------------------+------------+--------------------+--------------+\n|       Business_Area|      Action|         probability|predictedLabel|\n+--------------------+------------+--------------------+--------------+\n|Product: Availabi...|Free Upgrade|[0.0,1.0,0.0,0.0,...|  Free Upgrade|\n|Product: Availabi...|Free Upgrade|[0.0,1.0,0.0,0.0,...|  Free Upgrade|\n+--------------------+------------+--------------------+--------------+\nonly showing top 2 rows\n\n"}], "source": "predictions_action = model_action.transform(test_data)\npredictions_action.select('Business_Area','Action','probability','predictedLabel').show(2)"}, {"execution_count": 51, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Accuracy = 0.767442\n"}], "source": "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions_action)\n\nprint(\"Accuracy = %g\" % accuracy)"}, {"source": "<a id=\"persistence\"></a>\n## 4. Store the model in the repository", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "In this section you will store trained model to Watson Machine Learning repository. When model is stored some metada is optional, however we provide it to be able to configure Continuous Learning System.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"execution_count": 52, "cell_type": "code", "metadata": {}, "outputs": [], "source": "from watson_machine_learning_client import WatsonMachineLearningAPIClient"}, {"source": "We need Watson Machine Learning credentials to be able to store model in repository.", "cell_type": "markdown", "metadata": {}}, {"source": "**TIP:** Put watson Machine Learning service credentials here.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 54, "cell_type": "code", "metadata": {}, "outputs": [], "source": "wml_credentials = {\n  \"apikey\": \"***\",\n  \"iam_apikey_description\": \"***\",\n  \"iam_apikey_name\": \"***\",\n  \"iam_role_crn\": \"***\",\n  \"iam_serviceid_crn\": \"***\",\n  \"instance_id\": \"***\",\n  \"password\": \"***\",\n  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n  \"username\": \"***\"\n}"}, {"execution_count": 55, "cell_type": "code", "metadata": {}, "outputs": [], "source": "# The code was removed by Watson Studio for sharing."}, {"execution_count": 56, "cell_type": "code", "metadata": {}, "outputs": [], "source": "client = WatsonMachineLearningAPIClient(wml_credentials)"}, {"execution_count": 57, "cell_type": "code", "metadata": {}, "outputs": [{"execution_count": 57, "metadata": {}, "data": {"text/plain": "'1.0.328'"}, "output_type": "execute_result"}], "source": "client.version"}, {"source": "### 4.2 Save the pipeline and model<a id=\"save\"></a>", "cell_type": "markdown", "metadata": {}}, {"execution_count": 58, "cell_type": "code", "metadata": {}, "outputs": [], "source": "training_data_reference = {\n \"name\": \"CARS4U training reference\",\n \"connection\": db2_service_credentials,\n \"source\": {\n  \"tablename\": table_name,\n  \"type\": \"dashdb\"\n }\n}"}, {"source": "Define `output_data_schema` for the model", "cell_type": "markdown", "metadata": {}}, {"execution_count": 69, "cell_type": "code", "metadata": {}, "outputs": [], "source": "train_data_schema = train_data.schema\nlabel_field = next(f for f in train_data_schema.fields if f.name == \"Action\")\nlabel_field.metadata['values'] = string_indexer_action.labels"}, {"execution_count": 72, "cell_type": "code", "metadata": {}, "outputs": [], "source": "from pyspark.sql.types import *\n\ninput_fileds = filter(lambda f: f.name != \"Action\", train_data_schema.fields)\n\noutput_data_schema = StructType(list(input_fileds)). \\\n    add(\"prediction\", DoubleType(), True, {'modeling_role': 'prediction'}). \\\n    add(\"predictedLabel\", StringType(), True, {'modeling_role': 'decoded-target', 'values': string_indexer_action.labels}). \\\n    add(\"probability\", ArrayType(DoubleType()), True, {'modeling_role': 'probability'})"}, {"source": "print(json.dumps(output_schema.jsonValue(), indent=2))", "cell_type": "raw", "metadata": {}}, {"source": "Define model's metadata.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 75, "cell_type": "code", "metadata": {}, "outputs": [], "source": "model_props = {\n    client.repository.ModelMetaNames.NAME: \"CARS4U - Action Recommendation Model\",\n    client.repository.ModelMetaNames.TRAINING_DATA_REFERENCE: training_data_reference,\n    client.repository.ModelMetaNames.EVALUATION_METHOD: \"multiclass\",\n    client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA: output_data_schema.jsonValue(),\n    client.repository.ModelMetaNames.EVALUATION_METRICS: [\n        {\n           \"name\": \"accuracy\",\n           \"value\": accuracy,\n           \"threshold\": 0.7\n        }\n    ]\n}"}, {"source": "**Tip**: Use `client.repository.ModelMetaNames.show()` to get the list of available meta names.", "cell_type": "markdown", "metadata": {}}, {"source": "Store the model.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 76, "cell_type": "code", "metadata": {}, "outputs": [], "source": "published_model_details = client.repository.store_model(model=model_action, meta_props=model_props, training_data=train_data, pipeline=pipeline_action)"}, {"execution_count": 77, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "cad08901-3a59-47c6-a5a6-08439bcb4bc8\n"}], "source": "model_uid = client.repository.get_model_uid(published_model_details)\nprint(model_uid)"}, {"execution_count": 81, "cell_type": "code", "metadata": {}, "outputs": [], "source": "model_details = client.repository.get_model_details(model_uid)"}, {"source": "<a id=\"deploy\"></a>\n## 5. Deploy model in the IBM Cloud", "cell_type": "markdown", "metadata": {}}, {"source": "You can use following command to create online deployment in cloud.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 78, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: 'cad08901-3a59-47c6-a5a6-08439bcb4bc8' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='c71edbca-727c-4e7f-9cd7-99929c5b63bf'\n------------------------------------------------------------------------------------------------\n\n\n"}], "source": "deployment_details = client.deployments.create(model_uid=model_uid, name='CARS4U - Action Model Deployment')"}, {"source": "You can use deployed model to score new data using scoring endpoint.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 79, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "https://us-south.ml.cloud.ibm.com/v3/wml_instances/e30fe554-6e3e-4e0e-af06-90f93686f358/deployments/c71edbca-727c-4e7f-9cd7-99929c5b63bf/online\n"}], "source": "scoring_url = client.deployments.get_scoring_url(deployment_details)\nprint(scoring_url)"}, {"source": "<a id=\"score\"></a>\n## 6. Score the model", "cell_type": "markdown", "metadata": {}}, {"execution_count": 82, "cell_type": "code", "metadata": {}, "outputs": [], "source": "fields = ['ID', 'Gender', 'Status', 'Children', 'Age', 'Customer_Status','Car_Owner', 'Customer_Service', 'Business_Area', 'Satisfaction']\nvalues = [3785, 'Male', 'S', 1, 17, 'Inactive', 'Yes', 'The car should have been brought to us instead of us trying to find it in the lot.', 'Product: Information', 0]"}, {"execution_count": 96, "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Recommended action: \"Free Upgrade\"\n"}], "source": "payload_scoring = {\"fields\": fields,\"values\": [values]}\nscoring_response = client.deployments.score(scoring_url, payload_scoring)\n\nprint(\"Recommended action: \" + json.dumps(scoring_response['values'][0][21], indent=3))"}, {"source": "---", "cell_type": "markdown", "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3.5 with Spark 2.1", "name": "python3-spark21", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.4", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}